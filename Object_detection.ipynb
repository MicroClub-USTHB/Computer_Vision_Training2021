{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Object detection.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_S1wG91RfLQm"
      },
      "source": [
        "**Info**\r\n",
        "\r\n",
        "\r\n",
        "*   **Computer vision training camp** for Micro Club's 1st wave of internal trainings.\r\n",
        "* **Trainer:**  Sarra Laksaci -> SarraLKSC#7509 , saralaksaci@gmail.com\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWTs23FNNEzc"
      },
      "source": [
        ">  ![](https://www.solutions-numeriques.com/wp-content/uploads/2018/01/computer-vision-tasks.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UAcD9d6hmfdE"
      },
      "source": [
        "# **Problème**\r\n",
        ">**Detection des objets**\r\n",
        "\r\n",
        ">  D'un point de vu machine on dira qu'il s'agit de reconnaitres les différents object inclues dans une image mais aussi de les localiser dans cette image.\r\n",
        "\r\n",
        "> On peut donc déduire ici que la machine aura deux information à extraire de l'image présentée: \r\n",
        "* La classe d'un objet \r\n",
        "* Ses coordonées \r\n",
        "\r\n",
        ">Si l'on parle d'output, ces deux informations seront représentées par \r\n",
        "* Le label de sortie (comme dans une classification)\r\n",
        "* Le rectangle de detection représenté par un turple (x,y,h,w) \r\n",
        "\r\n",
        "> où x,y représentent les coordonées du coin supérieur gauche, et h,w représentent la hauteur et la largeur du rectangle à dessiner.\r\n",
        "\r\n",
        "> Comme à chaque challenge du domaine de Computer vision traité à l'aide de réseaux de neurones, on s'attend à recevoir des données labellisées. On parle donc d'apprentissage supervisé, ce qui signifie que pour qu'un objet soit detecté il doit tout d'abord faire partie de la liste de classes définis.\r\n",
        "\r\n",
        "> Contrairement à une classification, dans le problème de detection d'objet on aura toujours n+1 classes. La classe ajouté représente le fond de l'image. Pour un modèle de detection de chat et chien on aura donc les etiquettes suivantes [chat,chien,fond].\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "> ![](https://miro.medium.com/max/1276/1*HGWSXE8pFbAfB9zuCGXSQA.jpeg)\r\n",
        "\r\n",
        "> De manière simplifier on pourait décrire la detection d'objet comme une classification appliquée à des sous parties d'une meme image. L'algorithme applique les étapes suivantes: \r\n",
        "\r\n",
        "* Selectionner sous-image\r\n",
        "* Appliquer classification\r\n",
        "* Affiner la zone\r\n",
        "\r\n",
        "La classification étant un problème auquel nous avant déja la solution (you should know this by now) et la 3ème étape ne consistant qu'à réduire ou étendre le rectangle (pour se rapprocher au plus de l'objet) ... la partie la plus \"difficile\" revient donc à selectionner les sous-images (que l'on appelera dorénavant ROI \"*Region of interest*\".\r\n",
        "\r\n",
        "##Pourquoi est-ce primordiale de générer les bonne ROI?\r\n",
        "\r\n",
        "* Les objets peuvents etre de tailles différentes\r\n",
        "* Les objets peuvent se trouver n'importe ou dans l'image.\r\n",
        "\r\n",
        "Si on génére toutes les regions de toutes les tailles nous aurons alors une explosion combinatoire et l'execution de la classification sur la totalité des régions obtenues serait trop couteux \r\n",
        "\r\n",
        "![](https://www.pyimagesearch.com/wp-content/uploads/2020/06/region_proposal_object_detection_output_beagle_before.png)\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DEmVGSlhnDtu"
      },
      "source": [
        "# **Solution**\r\n",
        "\r\n",
        "Jusque là on sait qu'un modèle d'object detection aura en réalité deux missions ( deux output ) qui sont : **Généré le label** de l'objet et **générer son tuple** de coordonées. On sait aussi qu'avant d'en arriver là, il faut au préalable **retrouver les ROI**.\r\n",
        "\r\n",
        "Ces trois taches sont les trois étapes de la solution.\r\n",
        "Ce sont aussi les bloques de l'architecture mise en place pour solutionner cette problématique.\r\n",
        "\r\n",
        "### 1- Algorithmes de générations des ROI\r\n",
        "\r\n",
        "A ce niveau deux solution sont possibles: \r\n",
        "\r\n",
        "* Utiliser une algorithme de selective search (not AI)  ❌\r\n",
        "* Utiliser un modèle d'IA (Region Proposal Network) ✔\r\n",
        "\r\n",
        "###2- Classification pour les label\r\n",
        "\r\n",
        "Là aussi deux approches sont possibles:\r\n",
        "* Utiliser un SVM (another ML technique for classification) ❌\r\n",
        "*Utiliser un CNN (Convolutional neural networks that we saw before) ✔\r\n",
        "\r\n",
        "###3- Regression pour les BBox\r\n",
        "*Fully connected network (straight forward technique)\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZL8WyxeatJc"
      },
      "source": [
        "# **Les architectures**\r\n",
        "\r\n",
        "###1- RCNN ❌\r\n",
        ">>>![](https://i.stack.imgur.com/nwVF6.png)\r\n",
        "###2- Fast RCNN ❌\r\n",
        ">>>![](https://cdn.analyticsvidhya.com/wp-content/uploads/2018/10/Fast-rcnn.png)\r\n",
        "###3- Faster RCNN  ✔\r\n",
        ">>>>> ![](https://miro.medium.com/max/1940/1*pSnVmJCyQIRKHDPt3cfnXA.png)\r\n",
        "###4- Mask RCNN   ✔\r\n",
        "(on vera plus en detail ce model lors de la partie instance segmantation de la formation)"
      ]
    }
  ]
}