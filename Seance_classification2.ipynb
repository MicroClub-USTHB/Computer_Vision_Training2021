{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Seance_classification2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_S1wG91RfLQm"
      },
      "source": [
        "**Info**\r\n",
        "\r\n",
        "\r\n",
        "*   **Computer vision training camp** for Micro Club's 1st wave of internal trainings.\r\n",
        "* **Trainer:**  Sarra Laksaci -> SarraLKSC#7509 , saralaksaci@gmail.com\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXXpNKU0Gi4m"
      },
      "source": [
        "# **1-Correction du notebook envoyé**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eiqvL0zKjXzt"
      },
      "source": [
        "* notebook de solution [ici](https://colab.research.google.com/drive/12aJpTo-CQxcoynU3BaF_7rsuayD7e7lE?usp=sharing)\r\n",
        "\r\n",
        "* une autre version intéressante [ ici  ](https://colab.research.google.com/drive/1yj_bRbG9hYI6UzEUGtQn4cN-dHODFmZD?usp=sharing)\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g9Rdv9JDjxYF"
      },
      "source": [
        "####**Bug rencontrés**\r\n",
        "\r\n",
        "\r\n",
        "* **received a label value of i which is outside the valide range of [0,j)**\r\n",
        "\r\n",
        " -> L'un des label y attribué aux images du dataset d'entrainement ne fait pas partie de l'ensemble de définition des étiquettes. \r\n",
        "\r\n",
        "   L'ensemble de définition des étiquettes est défini à travers l'architecture du réseau x aka la couche de sortie -> pour n classes output layer de n neurones.\r\n",
        "\r\n",
        "\r\n",
        "* Le choix du kernel size d'une opération de pooling\r\n",
        "![](https://www.researchgate.net/profile/Gianni_Di_Caro/publication/262686509/figure/fig2/AS:296519627493376@1447707196044/Effect-of-the-convolutional-and-max-pooling-kernel-sizes-C-x-C-y-and-M-x-M-y.png)  ref: [Effect of the convolutional and max-pooling kernel sizes ( ( C x , C y ) and ( M x , M y ) respectively) on the performance of the learning scheme.](https://www.researchgate.net/figure/Effect-of-the-convolutional-and-max-pooling-kernel-sizes-C-x-C-y-and-M-x-M-y_fig2_262686509)\r\n",
        ">\"\r\n",
        "....*We first study the effect of using different convolution ( C x , C y ) and max-pooling ( M x , M y ) kernel sizes on the performance of the SCW learning scheme, as shown in Figure 4. For instance, C ( 5 , 5 ) represents a convolution kernel of size ( 5 × 5 ) , and similarly M ( 3 , 3 ) indicates a max-pooling kernel of size ( 3 × 3 ) . The online mistake rate, as shown on the left of Figure 4, is highly influenced by the size of the kernels used to learn and represent the features. **It results that the size of the max-pooling kernel should always be small (e.g. 3 × 3 or 2 × 2), so that during pooling operations there is not a heavy loss of information in the quality of the features.** Convolution kernels with sizes greater than ( 5 × 5) do not provide good representations of the features, due to the many invariances (rotation, scale and translation) in our dataset. The most optimal combination of the kernel parameters that produce lowest mistake are convolution kernel of size ( 5 × 5 ) and max-pooling kernel of size ( 2 × 2 )*.....\"\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        ">**Rappel** \r\n",
        "\r\n",
        ">Pooling : Permet de réduire la taille des données en gardant l’information essentielle et en supprimant les redondances, ce qui facilite l’application des calculs sans perte de l’efficacité.\r\n",
        "\r\n",
        "Donc plus la taille du pooling est grande plus on va \"negliger\" des informations et gagner de l'abstraction ce qui accelère les calculs mais appovrit les performances\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "**Aussi faire attention aux divisions qui ont lieu lors du changement de dimensions des nos matrices ça peut donner lieu à des exceptions**\r\n",
        "\r\n",
        "La formule de calcule de la taille de la feature map est la suivante\r\n",
        "\r\n",
        "$O = (W - K + 2P)/S + 1$\r\n",
        "* O : ordre de la matrice de sortie de la couche\r\n",
        "* W : ordre de la matrice d'entrée dans la couche \r\n",
        "* K : ordre de la matrice du kernel\r\n",
        "* P : padding\r\n",
        "* S : stride\r\n",
        "\r\n",
        "Dans certain cas un mauvais choix du Kernel size du pooling peut gén"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ztJ6nn42GcEA"
      },
      "source": [
        "# **2-Classification sur données réelles**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rvUsUVlpJvDx"
      },
      "source": [
        ">jusqua là on a pu voir comment mettre au point un réseau convolutif pour résoudre un problème de classification d'images. Les images utilisées lors de nos exemples (binaire, naire, travail à faire) proviennent de dataset présentés par le module Tensorflow Dataset. \r\n",
        "\r\n",
        ">tfds facilite grandement la partie de traitement et préparation des données qui précède la construction du mmodèle.Dans la majorité des cas (pour ne pas dire 100% des cas) un travail fastidieux est nécessaire en ce qui concerne les données (chargement, augmentation...) \r\n",
        "\r\n",
        "**ImageDataGenerator est la solution**\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "ImageDataGen permet de : \r\n",
        "* charger les images et les triés directement a partir du dossier présenté\r\n",
        "* appliquer tout traitement nécessaire (normalization, resize...)\r\n",
        "* appliquer l'augmentation des données dynamiquement lors de l'entrainement\r\n",
        "\r\n",
        ">-indirectement ceci nous permet aussi de palier au problème d'overfitting qu'on peut avoir étant donné qu'un dataset plus grand à moins de chances de faire de l'overfitting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZF5ypiewZOpZ"
      },
      "source": [
        "##Comment travailler avec ImageDataGen\r\n",
        "\r\n",
        "* Exemple cats_and_dogs [ici](https://colab.research.google.com/drive/15CArMcJp3PZm9XCjEBZJc4irByDyM8Bq?usp=sharing)"
      ]
    }
  ]
}